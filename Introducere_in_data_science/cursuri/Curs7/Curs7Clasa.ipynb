{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curs 6: Optimizarea modelelor, preprocesare, pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizarea modelelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cursul anterior s-a aratat cum se poate folosi k-fold cross validation pentru estimarea performantei unui model. Totodata, s-a aratat o maniera simpla de cautare a valorilor celor mai potrivite pentru hiperparametri - in cazul respectiv. valoarea adecvata a numarului de vecini. \n",
    "\n",
    "Vom continua aceasta idee pentru mai multi hiperparametri, apoi folosim facilitatile bibliotecii `sklearn` pentru automatizarea procesului."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation ( asigura ca fiecare din cele k partitii ale setului de date initial este pe rand folosit ca subset de testare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:41:03.911845Z",
     "start_time": "2020-04-06T15:41:01.030797Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "!pip install prettytable --upgrade\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T15:41:04.076388Z",
     "start_time": "2020-04-06T15:41:03.924791Z"
    }
   },
   "outputs": [],
   "source": [
    "kf = ...\n",
    "splits = ...\n",
    "t = PrettyTable(['Iter', 'Train', 'Test'])\n",
    "t.align = 'l'\n",
    "for i, data in enumerate(splits):\n",
    "    t.add_row([i+1, data[0], data[1]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru calculul performantei prin k-fold CV se asigura ca esantionarea se face in mod stratificat: fiecare fold are aceeasi proportie a claselor ca si in setul originar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folosim k-fold cross validation pentru a face evaluarea de modele pentru diferite valori ale hiperparametrilor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print ('numpy: ', np.__version__)\n",
    "print ('pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ...\n",
    "from sklearn.neighbors import ...\n",
    "from sklearn.metrics import ...\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = ...\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru k-nearest neighbors vom cauta valorile optime pentru:\n",
    "* numarul de vecini, $k \\in \\{1, \\dots, 31\\}$\n",
    "* putere corespunzatoare metricii Minkowski:\n",
    "$$\n",
    "d(\\mathbf{x}, \\mathbf{y}) = \\left( \\sum\\limits_{i=1}^n \\left|x_i-y_i\\right|^p \\right)^{1/p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "for k in range(1, 31):\n",
    "    for p in [1, 2, 3, 4.7]:\n",
    "        ...\n",
    "print('Best score:', best_score)\n",
    "print('Best params:', best_params)   \n",
    "model = ...\n",
    "model.fit(X, y)\n",
    "y_predicted = model.predict(X)\n",
    "print('Accuracy on whole set:', accuracy_score(y, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru procesul de mai sus urmatoarele comentarii sunt necesare:\n",
    "1. strategia implementata se numeste grid search: se cauta peste toate combinatiile de 30\\*4 variante si sa retine cea mai buna; este consumatoare de resurse, dar o prima varianta de lucru acceptabila\n",
    "1. am dori sa avem o modalitate automatizata de considerare a tuturor combinatiilor de parametri din multimea de valori candidat. Codul devine greu de scris cand sunt multi hiperparametri, fiecare cu multimea proprie de valori candidat\n",
    "1. estimarea efectuata in final este de cele mai multe ori optimista: optimizarea parametrilor s-a facut peste niste date, care date in final sunt cele folosite pentru evaluarea finala; am ajuns practic sa facem evaluare pe setul de antrenare, ceea ce e o idee proasta. Estimarea finala a performantelor modelului trebuie facuta peste un set de date aparte, care nu a fost folosit nici pentru antrenare, nici pentru validarea modelelor candidat. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru ultimul punct se recomanda ca setul sa fie impartit ca mai jos:\n",
    "![train_validation_test](./images/train_validation_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca atare, va trebui sa rescriem codul astfel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/5)\n",
    "...\n",
    "print('Best score:', best_score)\n",
    "print('Best params:', best_params)   \n",
    "\n",
    "model = ...\n",
    "model.fit...\n",
    "y_predicted = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desigur, si implementarea de mai sus e criticabila: s-a facut evaluare pe un singur set de testare, anume cel rezultat dupa impartirea initiala in partitiile \\*\\_trainvalid si \\*\\_test. Este totusi o estimare mai corect facuta decat cea precedenta.  In realitate, acest stil de lucru este frecvent intalnit: exista un set de testare unic, dar necunoscut la inceput. Singurele date disponibile sunt impartite in *training set* si *validation set* (eventual mai multe) pentru a obtine un model care se spera ca generalizeaza bine = se comporta bine pe setul de testare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varianta anterioara se numeste **grid search with cross validation**. Exista clasa `sklearn.model_selection.GridSearchCV` care automatizeaza procesul:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/5)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_estimated = grid_search.predict(X_test)\n",
    "print(accuracy_score(y_test, y_estimated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valorile optimale ale hiperparametrilor sunt retinute in atributul `best_params_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T16:51:26.063626Z",
     "start_time": "2020-04-06T16:51:25.932974Z"
    }
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In codul anterior denumirile cheilor din dictionarul `parameter_grid` nu sunt intamplatoare: ele coincid cu numele parametrilor modelului vizat. Instantierea `estimator = KNeighborsClassifier()` se face cu valorile implicite ale parametrilor, apoi insa se ruleaza metode de tip `set_` care seteaza parametrii dati in dictionarul `parameter_grid`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru cei interesati, valorile de performanta pentru fiecare fold se pot inspecta in campul `cv_results_`. Pentru ca acestea sa fie disponibile, este obligatorie setarea parametrului `return_train_score=True` din clasa `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid_search.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru situatia in care se doreste evaluarea nu doar pe un singur set de testare, ci in stil cross-validation, se poate face un *nested cross-validation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode de preprocesare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uneori, inainte de aplicarea vreunui model, este nevoie ca datele de intrare sa fie supuse unor transformari. De exemplu, daca pentru algoritmul k-NN vreuna din trasaturi (fie ea *F*) are valori de ordinul sutelor si celelalte de ordinul unitatilor, atunci distanta dintre doi vectori ar fi dominata de diferenta pe dimensiunea *F*; celelalte dimensiuni nu ar conta prea mult.\n",
    "\n",
    "Intr-o astfel de situatie se recomanda sa se faca o scalare in prealabil a datelor la intervale comparbile, de ex [0, 1]. \n",
    "\n",
    "In modulul `sklearn.preprocessing` se afla clasa `MinMaxScaler` care permite scalarea independenta a trasaturilor. Il vom demonstra pe un set de date care are trasaturi cu marimi disproportionate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ranges(X):\n",
    "    ...\n",
    "        \n",
    "print_ranges(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "...\n",
    "print_ranges(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De mentionat ca secventa `fit` si `transform` se poate apela intr-un singur pas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = medical.data, medical.target\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De regula, setul de date se imparte in doua (in modul naiv): set de antrenare si set de testare. Se presupune ca setul de testare este cunoscut mult mai tarziu decat cel de antrenare. Ca atare, doar cel de antrenare se trece prin preprocesor, iar  valorile 'invatate' via `fit ` se pastreaza (obiectul de tip `MinMaxScaler` are stare). Ele vor fi folosite pentru scalarea setului de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)\n",
    "scaler = MinMaxScaler()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se remarca faptul ca, folosindu-se parametrii de scalare din setul de antrenare, nu se poate garanta ca setul de testare este cuprins de asemenea in hipercubul unitate $[0, 1]^{X.shape[1]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exista si alte metode de preprocesare in modulul [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/preprocessing.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prefera inlantuirea intr-un proces a pasilor: preprocesare si aplicare de model. Exemplificam pentru cazul simplu in care exista un set de antrenare si unul de testare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = medical.data, medical.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru cazul in care se vrea k-fold cross validation pentru determinarea valorilor optime pentru hiperparametri, urmata de testare pe un set de testare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:29:25.620073Z",
     "start_time": "2019-04-03T19:29:24.438930Z"
    }
   },
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=1/3)\n",
    "parameter_grid = {'knn__n_neighbors': list(range(1, 10)), 'knn__p': [1, 2, 3, 4.7]}\n",
    "grid = GridSearchCV(pipe, param_grid = parameter_grid, scoring = 'accuracy', cv=5)\n",
    "grid.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
