{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curs 6: Regresia liniara, evaluarea si selectarea naiva a modelelor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prin regresie se doreste estimarea unei valori continue: temperatura sau presiunea dintr-un proces fizic, valoarea estimata pentru un serviciu/bun cumparat etc. Prin comparatie, clasificarea dorea estimarea unei valori de iesire dintr-o multime finita de posibilitati (clase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresia liniara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplu de problema\n",
    "\n",
    "Sa presupunem ca dorim sa modelam pretul de vanzare al unei proprietati imobiliare, *e.g.* o casÄƒ. Se cunosc $p$ cazuri de vanazare-cumparare de case. Fiecare casa vanduta este descrisa printr-un set de trasaturi (eng: features) cum ar fi: suprafata (sau numarul de camere), distanta de la ea pana la centrul orasului, gradul de poluare a zonei etc. - toate valori numerice. De asemenea, pentru fiecare casa se cunoaste care a fost pretul de vanzare-cumparare. Un astfel de set de date este [Boston housing](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). \n",
    "\n",
    "Se doreste a se construi un model care, plecand de la datele furnizate, sa fie capabil sa \"invete\" sa aproximeze valoarea unei noi proprietati pentru care valorile de intrare (trasaturile) se cunosc.\n",
    "\n",
    "Avem de-a face cu:\n",
    "* problema de instruire supervizata (se cunosc asocieri intre trasaturi de intrare - valoare de iesire);\n",
    "* problema de regresie - valoarea estimata este una continua, nu dintr-o multime predefinita de clase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresia liniara\n",
    "\n",
    "Se poate consulta Cursul 2 din [Sisteme computationale inteligente, note de curs](https://github.com/lmsasu/cursuri/blob/master/SistemeComputationaleInteligente/SistemeComputationaleInteligente.pdf), pentru expunere mai ampla, algoritm de instruire bazat pe cautare dupa directia gradientului (stochastic gradient descent) si metoda ecuatiilor normale. O scurta descriere este data mai jos. \n",
    "\n",
    "Notatii:\n",
    "* $x_1, x_2, \\dots, x_n$: valorile numerice aferente unei case: suprafata, distanta pana la centrul orasului etc. \n",
    "* $\\theta_0, \\theta_1, \\dots, \\theta_n$ sunt coeficienti care trebuie determinati. Se observa ca avem cu un coeficient mai mult decat valori de trasaturi. \n",
    "\n",
    "In regresia liniara se presupune ca valoarea de iesire (pretul) variaza liniar cu valorile trasaturilor de intrare. Se noteaza un astfel de model cu $h$; dependenta lui de un vector de coeficienti - numit si vectori de ponderi (eng: weights) - se marcheaza explicit prin notatia $h_\\theta$. Forma modelului este:\n",
    "$$\n",
    "h_{\\theta}(\\mathbf{x}) = \\theta_0 + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\dots +\\theta_n \\cdot x_n\n",
    "$$\n",
    "Primul termen al expresiei de dupa egal se poate scrie sub forma: $\\theta_0 \\cdot 1$. Daca notam cu $x_0$ valoarea constanta 1, asta ne permite sa consideram doi vectori cu $n+1$ componente:\n",
    "* $\\mathbf{x} = \\begin{pmatrix}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{pmatrix}\n",
    "$ este vectorul de intrare continand caracteristicile numerice ale unei case oarecare;\n",
    "* $\\boldsymbol{\\theta} = \\begin{pmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_n\n",
    "\\end{pmatrix}\n",
    "$ este vectorul de coeficienti.\n",
    "\n",
    "Relatia de mai sus pentru $h_{\\theta}$ se scrie mai concis astfel:\n",
    "$$\n",
    "    h_\\theta(\\mathbf{x}) =  \\boldsymbol{\\theta}^t \\cdot \\mathbf{x} \n",
    "$$\n",
    "care in NumPy se scrie cu \n",
    "```python\n",
    "np.dot(theta, x)\n",
    "```\n",
    "sau \n",
    "```python\n",
    "theta @ x\n",
    "```\n",
    "\n",
    "Ceea ce trebuie facut este determinarea coeficientilor din vectorul $\\boldsymbol{\\theta}$ pentru care valoarea medie a patratelor diferentelor dintre estimarea facuta de model pentru valoarea de vanzare a unei case si valoarea ei cunoscuta sa fie cat mai mica:\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2p} \\sum\\limits_{i=1}^p \\left( h_{\\theta}(\\mathbf{x}_i) - y_i \\right)^2\n",
    "$$\n",
    "unde: $p$ este numarul de cazuri de vanzare cunoscute, $\\mathbf{x}_i$ este vectorul de trasaturi pentru casa $i$, $y_i$ este suma cu care s-a vandut aceasta casa. \n",
    "\n",
    "Modelul rezultat este simplu, popular, interpretabil. Poate fi insa prea simplist pentru destul de multe cazuri (underfitting).  \n",
    "\n",
    "Sunt doua variante de determinarea a acelui vector de coeficienti $\\boldsymbol{\\theta}$ care face ca valoarea functiei de eroare sa fie minima. Cititorul poate consulta cursul indicat la inceputul sectiunii. Noi vom folosi implementari din biblioteca scikit learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setul de date\n",
    "\n",
    "Setul de date este [Boston housing](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/): \"Concerns housing values in suburbs of Boston\", cu 506 instante (case vandute), 13 trasaturi de intrare. Toate valorile sunt precizate. Descrierea setului de date se gaseste [aici](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citirea datelor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T12:27:07.674236Z",
     "start_time": "2021-04-06T12:27:04.478629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 1.2.3\n",
      "sklearn version: 0.24.1\n",
      "numpy version: 1.20.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import sklearn\n",
    "\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'sklearn version: {sklearn.__version__}')\n",
    "print(f'numpy version: {np.__version__}')\n",
    "\n",
    "# Pandas version: 1.2.3\n",
    "# sklearn version: 0.24.1\n",
    "# numpy version: 1.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_housing = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "url_housing = './data/housing.data'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citire date, delimitator regex\n",
    "data_house = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T12:39:18.866177Z",
     "start_time": "2021-04-06T12:39:17.790341Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_house' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-69ac06311347>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_house\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_house' is not defined"
     ]
    }
   ],
   "source": [
    "data_house.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impartirea setului de date in set de antrenare si set de testare\n",
    "\n",
    "Ca si in cazul problemelor de clasificare, o parte din date vor fi folosite pentru antrenare, iar modeul rezultate va fi testat pe restul de date - setul de testare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separare X si y\n",
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprezentare de valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "#reprezentare RM versus price\n",
    "\n",
    "plt.scatter(X_train[:, 5], y_train)\n",
    "plt.xlabel('average number of rooms per dwelling')\n",
    "plt.ylabel('Median value of owner-occupied homes in $1000''s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reprezentare fiecare trasatura de intrare fata de pret\n",
    "for index, name in enumerate(names[:-1]):\n",
    "    plt.scatter(X_train[:, index], y_train)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Median value of owner-occupied homes in $1000''s')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construirea modelului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiere model LinearRegression, antrenare\n",
    "model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiparirea coeficientilor rezultati\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictie pe setul de test\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afisarea primelor trei predictii\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculare metricilor de eroare\n",
    "\n",
    "Ne intereseaza cat de deparrate sunt valorile prezise de cele actuale. Aceasta se face pe baza unor metrici de eroare. Sunt mai multe metrici care se pot considera pentru o problema de regresie:\n",
    "1. Mean absolute error (MAE):\n",
    "$$\n",
    "MAE = \\frac{1}{p}\\sum\\limits_{i=1}^p \\left|y_i - \\hat{y}_i\\right|\n",
    "$$\n",
    "unde $p$ e numarul de cazuri peste care modelul a produs estimari - de exemplu, numarul de cazuri din setul de testare.\n",
    "1. Root mean squared error (RMSE):\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{p} \\sum\\limits_{i=1}^p (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "1. Intrucat functia radical este crescatoare, se prefera uneori a se renunta la radical, obtinand Mean squared error (MSE):\n",
    "$$\n",
    "MSE = \\frac{1}{p} \\sum\\limits_{i=1}^p (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "In sklearn exista modulul `sklearn.metrics` care contine functii si clase dedicate calculului metricilor de eroare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem incerca cu diferite subsetui de trasaturi. De exemplu, atributul CHAS este descris in documentatie ca 'Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)'. Putem incerca sa vedem cum functioneaza modelul de regresie fara el:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_woCHAS = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noCHAS = data_house_noCHAS.values[:, :-1]\n",
    "y_noCHAS = data_house_noCHAS.values[:, -1]\n",
    "\n",
    "X_train_noCHAS, X_test_noCHAS, y_train_noCHAS, y_test_noCHAS = train_test_split(X_noCHAS, y_noCHAS, test_size=0.34, random_state=10)\n",
    "\n",
    "#instantiere model, antrenare\n",
    "model = LinearRegression(normalize=False)\n",
    "model.fit(X_train_noCHAS, y_train_noCHAS)\n",
    "\n",
    "#predictie pe setul de test\n",
    "y_hat = model.predict(X_test_noCHAS)\n",
    "\n",
    "mae = metrics.mean_absolute_error(y_test_noCHAS, y_hat)\n",
    "mse = metrics.mean_squared_error(y_test_noCHAS, y_hat)\n",
    "rmse = np.sqrt(mse)\n",
    "print('mae={0}, mse={1}'.format(mae, mse))\n",
    "\n",
    "# se remarca o usoara inrautatire a ambelor scoruri. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model liniar cu regularizare L1, L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularizarea are ca scop reducerea in valoare absoluta a coeficientilor $\\theta_1, \\theta_2, \\dots, \\theta_n$ (se remarca absenta termenului liber din multimea coeficientilor regularizati). Daca coeficientii sunt mari in valoare absoluta, atunci variatii mici ale valorilor de intrare duc la variatii mari ale iesirii, ceea ce corespunde unui sistem instabil.\n",
    "\n",
    "Functia de cost se modifica astfel:\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2p} \\sum\\limits_{i=1}^p \\left( h_{\\theta}(\\mathbf{x}_i) - y_i \\right)^2 + \\lambda \\cdot \\sum\\limits_{j=1}^{n} \\theta_j^2\n",
    "$$\n",
    "\n",
    "Implementarea in `sklearn` este continuta in biblioteca `sklearn.linear_model` in clasa `Ridge`. \n",
    "\n",
    "Exista si varianta in care termenul de regularizare se bazeaza pe valorile absolute ale coeficientilor:\n",
    "$$\n",
    "J(\\boldsymbol{\\theta}) = \\frac{1}{2p} \\sum\\limits_{i=1}^p \\left( h_{\\theta}(\\mathbf{x}_i) - y_i \\right)^2 + \\lambda \\cdot \\sum\\limits_{j=1}^{n} \\left|\\theta_j\\right|\n",
    "$$\n",
    "Modelul corespunzator se numeste Lasso (Least Absolute Shrinkage and Selection Operator), iar implementarea se afla in clasa `Lasso` din acelasi pachet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "mae = metrics.mean_absolute_error(y_test, y_hat)\n",
    "mse = metrics.mean_squared_error(y_test, y_hat)\n",
    "\n",
    "print(\"mae={0}, mse={1}\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(alpha=0.001)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "mae = metrics.mean_absolute_error(y_test, y_hat)\n",
    "mse = metrics.mean_squared_error(y_test, y_hat)\n",
    "\n",
    "print(\"mae={0}, mse={1}\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Evaluarea modelelor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluarea calitatii unui model se poate face pe:\n",
    "1. setul de antrenare - dar acest stil de lucru tinde sa favorizeze aparitia unor modele complexe, care invata bine setul de antrenare, dar nu generalizeaza bine in afara lui (overfitting)\n",
    "1. un set de testare separat fata de setul de antrenare - o idee mai buna, care tinde sa incurajeze modelele care se comporta bine si pe altceva decat setul de antrnare; overfitting-ul este redus ca incidenta; totusi, exista o problema: rezultatul evaluarii depinde de o unica masuratoare - pe unicul set de date de testare, deci poate fi prea optimista sau prea pesimista;\n",
    "1. mai multe seturi de testare; in particular, putem cere impartirea unui set de testare in $k$ subseturi de dimensiuni (cat mai) egale; pe rand, fiecare din cele $k$ seturi este folosit drept set de testare, iar celelalte $k-1$ subseturi sunt pentru antrenarea modelului La final se face media celor $k$ scoruri, determinand un scor mediu, mai apropiat de realitate. varianta descrisa se numeste k-fold cross validation si este reprezentata mai jos pentru $k=10$:\n",
    "![k fold cross validation](./images/k-fold-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplificare: k-fold cross validation pentru un model de clasificare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vom folosi pentru exemplificare k-NN; nu exista nicio legatura intre $k$ -- numarul de vecini si $k$ - numarul de fold-uri considerat, cele doua folosind intamplator aceeasi litera pentru a denota un hiperparametru al modelului, respectiv numarul de partitii ale setului de antrenare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In primul pas vom demonstra variabilitatea rezultatelor instruirii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterare peste 5 partitionari aleatoare\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem face o medie a numerelor rezultate si aceasta valoare este o estimare mai realista a performantei clasificatorului. Prin k-fold cross validation, insa, se are in vedere ca fiecare inregistrare din setul initial sa fie folosit pentru testare, in mod garantat. De asemenea, fiecare inregistrare se foloseste pentru antrenare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desigur, nimic nu ne opreste sa repetam k-fold cross validation pentru diferite permutari initiale ale setului de antrenare si sa calculam la final media rezultatelor (media mediilor). Estimarea este mai robusta, dar mare consumatoare de timp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raportarea rezultatelor de pe setul de antrenare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este posibila sa se ceara raportarea rezultatelor pentru fold-urile care au fost folosite la antrenare. Acest demers este util pentru cazurile in care se suspecteaza overfit: rezultatele de pe setul de antrenare sunt excelente, dar cele de pe setul de testare sunt mult mai proaste. \n",
    "\n",
    "De asemenea, se poate inregistra timpul cerut de procesul de antrenare\n",
    "\n",
    "Raportarea rezultatelor se face cu functia `cross_validate` din modulul `sklearn.model_selection`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "results = cross_validate(model, X, y, cv=3, scoring='accuracy', return_train_score=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectarea manuala a modelului"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valorea hiperparametrului $k$ a fost aleasa mai sus in mod arbitrar. Se pune problema: care este cea mai buna valoare a lui $k$? Putem face acest lucru printr-o cautare sistematica a lui $k$, de exemplu $k \\in \\{ 1, 2, \\dots, 20 \\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T19:17:06.179063Z",
     "start_time": "2021-04-06T19:17:05.795490Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bd35d63b30db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mrange_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mscores_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmean_score_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_k\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Max score obtained for: {0} with value: {1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-bd35d63b30db>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mrange_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mscores_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmean_score_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_k\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Max score obtained for: {0} with value: {1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-bd35d63b30db>\u001b[0m in \u001b[0;36mmean_score_for_model\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     :return: mean of scores over 10 fold CV\"\"\"\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "def mean_score_for_model(k):\n",
    "    \"\"\"Creates and train a KNeighborclassifier with number of neighbors given by :param k:\n",
    "    :param k: number of neighbors\n",
    "    :return: mean of scores over 10 fold CV\"\"\"\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "range_k = range(1, 35)\n",
    "scores_k = [mean_score_for_model(k) for k in range_k]\n",
    "\n",
    "print('Max score obtained for: {0} with value: {1}'.format(1+np.argmax(scores_k), np.max(scores_k)))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range_k, scores_k);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impartirea setului de date in mod stratificat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atunci cand se face impartirea pe setul de date, este bine sa ne asiguram ca subsetul de antranre si cel de testare contin aceeasi proportie intre clasele din submultimile de antrenare si de testare. \n",
    "\n",
    "**Exemplu:** pentru setul de date iris, numarul de cazuri din fiecare clasa este egal (50). Dorim ca pentru fiecare subset (de antrnare si de testare) sa avem ca numarul de cazuri pentru fiecare clasa de floare de iris sa fie aproximativ acelasi. Asta ne permite sa evitam o situatie in care subsetul de antrenare are doar flori de doua clase iar subsetul de testare doar flori din a treia clasa. Pentru asta se foloseste stratified sampling - esantionare stratificata.\n",
    "\n",
    "Pentru sklearn functia care realizeaza impartirea stratificata in fold-uri este [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) - ca si inainte - cu parametrul suplimentar `stratify`: \"If not None, data is split in a stratified fashion, using this as the class labels.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(f'Numarare de elemente in setul de antrenare: {Counter(y_train)}')\n",
    "print(f'Numarare de elemente in setul de testare: {Counter(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acest lucru trebuie considerat, desigur, si la partea de cross-validation: se va prefera un stratified cross validatin pentru probleme de testare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
